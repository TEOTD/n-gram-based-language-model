from collections import Counter, defaultdict
import logging
import numpy as np
import random
import typing

smoothing_value = 1e-8
train_path = "A1_DATASET/train.txt"
val_path = "A1_DATASET/val.txt"

# Set logging / print options
logging.basicConfig(level=logging.ERROR)
logger = logging.getLogger(__name__)
np.set_printoptions(precision=3)

def preprocess_line(line: str, dict: set[str] = None) -> typing.List[str]:
    """
    Turns a line string into a list of tokens. Adds <start> and <end> to the start and end.

    Inputs:
        line: The input line string.
        dict: Optional set of known tokens. Unknown tokens will be replaced with <unk>.

    Returns:
        The preprocessed list of tokens.
    """
    l = line.strip().split()
    l.insert(0, '<start>')
    l.append('<end>')

    if dict is not None:
        l = [token if token in dict else '<unk>' for token in l]
    return l

with open(train_path, "r") as f:
    train_corpus = list(map(preprocess_line, f.readlines()))

token_dict = {'<start>', '<end>', '<unk>'}
for line in train_corpus:
    for token in line:
        token_dict.add(token)

# Unigram model

word_count = sum(len(line) for line in train_corpus)

unigram_freq = Counter()
for line in train_corpus:
    for token in line:
        unigram_freq[token] += 1

unigram_probs = {token: count / word_count for token, count in unigram_freq.items()}
tokens = list(unigram_probs.keys())
freqs = list(unigram_probs.values())

for i in unigram_probs:
    logger.info(f"Unigram '{i}': {unigram_probs[i]}")

def unigram_model(line: typing.List[str]) -> float:
    """
    Returns the probability of a random line generated by the unigram model.

    Inputs:
        line: A list of tokens representing the line.
    
    Returns:
        A float representing the natural log of the probability of the line.
    """
    prob = 0
    for token in line:
        prob += np.log(unigram_probs.get(token, smoothing_value))
    return prob

# Bigram model

bigram_freq = defaultdict(Counter)
for line in train_corpus:
    for i in range(len(line)-1):
        bigram_freq[line[i]][line[i+1]] += 1

bigram_probs = {}
for token, counter in bigram_freq.items():
    total_count = sum(counter.values())
    bigram_probs[token] = {t: c / total_count for t, c in counter.items()}

for i in bigram_probs:
    logger.info(f"Bigram '{i}': {bigram_probs[i]}")

def bigram_model(line: typing.List[str]) -> float:
    """
    Returns the probability of a random line generated by the bigram model.

    Input:
        line: A list of tokens representing the line.
    
    Output:
        A float representing the natural log of the probability of the line.
    """
    prob = 0
    for i in range(1, len(line)):
        bigram = (line[i-1], line[i])
        prob += np.log(bigram_probs.get(bigram[0], {}).get(bigram[1], smoothing_value))
    return prob

# Validation tests

with open(val_path, "r") as f:
    val_corpus = []
    for line in f.readlines():
        val_corpus.append(preprocess_line(line, token_dict))
    for line in val_corpus:
        unigram_prob = np.array([unigram_model(line)])
        bigram_prob = np.array([bigram_model(line)])
        print (" ".join(line))
        print (f"Unigram prob: {unigram_prob}")
        print (f"Bigram prob: {bigram_prob}")